{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db6bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "                      ################## Test The Model ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffe92c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3761eaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen=ImageDataGenerator(rescale = 1./255, shear_range=0.2, zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fec4780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12845 images belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory(r\"C:\\Program Files\\Data Collection\\train\\train\", target_size=(64,64),batch_size=100,\n",
    "                                            class_mode='categorical', color_mode =\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6e2b361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4268 images belonging to 27 classes.\n"
     ]
    }
   ],
   "source": [
    "x_test = test_datagen.flow_from_directory(r\"C:\\Program Files\\Data Collection\\test\\test\", target_size=(64,64),batch_size=100,\n",
    "                                         class_mode='categorical', color_mode =\"grayscale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e273197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d495c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afc0042a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " 'A': 1,\n",
       " 'B': 2,\n",
       " 'C': 3,\n",
       " 'D': 4,\n",
       " 'E': 5,\n",
       " 'F': 6,\n",
       " 'G': 7,\n",
       " 'H': 8,\n",
       " 'I': 9,\n",
       " 'J': 10,\n",
       " 'K': 11,\n",
       " 'L': 12,\n",
       " 'M': 13,\n",
       " 'N': 14,\n",
       " 'O': 15,\n",
       " 'P': 16,\n",
       " 'Q': 17,\n",
       " 'R': 18,\n",
       " 'S': 19,\n",
       " 'T': 20,\n",
       " 'U': 21,\n",
       " 'V': 22,\n",
       " 'W': 23,\n",
       " 'X': 24,\n",
       " 'Y': 25,\n",
       " 'Z': 26}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a06b4570",
   "metadata": {},
   "outputs": [],
   "source": [
    "        ###################### Import The Packages And Load The Saved Model ######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3337b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6b1c851",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the model\n",
    "model=Sequential()\n",
    "#Adding the layers\n",
    "model.add(Convolution2D(32,(3,3), input_shape=(64,64,1), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "\n",
    "#adding hidden layers\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "#Adding the output layer\n",
    "model.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd2c1316",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43c94ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-27-5b5a37433cda>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - ETA: 0s - loss: 1.1565 - accuracy: 0.6160WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "30/30 [==============================] - 21s 697ms/step - loss: 1.1565 - accuracy: 0.6160 - val_loss: 0.5600 - val_accuracy: 0.8102\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 15s 504ms/step - loss: 0.3481 - accuracy: 0.8922\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 15s 509ms/step - loss: 0.1948 - accuracy: 0.9447\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 15s 516ms/step - loss: 0.1390 - accuracy: 0.9553\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 15s 511ms/step - loss: 0.0763 - accuracy: 0.9790\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 15s 505ms/step - loss: 0.0560 - accuracy: 0.9843\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 15s 501ms/step - loss: 0.0506 - accuracy: 0.9877\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 15s 497ms/step - loss: 0.0466 - accuracy: 0.9867\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 15s 502ms/step - loss: 0.0488 - accuracy: 0.9857\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 15s 490ms/step - loss: 0.0454 - accuracy: 0.9841\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f2fe4f1a30>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train, steps_per_epoch=30, epochs=10, validation_data=x_test,validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df8eda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('HandSign.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3e1ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Load The Test Image, Pre-Process It And Predict #############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85161549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "962b1434",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"C:\\Program Files\\HandSign.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c8edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('C:\\\\Program Files\\\\Data Collection\\\\test\\\\test\\\\A\\\\11.jpg',target_size = (100,100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4354b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x2063AF6A1F0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a04d893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "def detect(frame):\n",
    "    img=image.img_to_array(frame)\n",
    "    img = resize(img,(64,64,1))\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    pred=np.argmax(model.predict(img))\n",
    "    op=['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "    print(\"THE PREDICTED LETTER IS \",op[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b81da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PREDICTED LETTER IS  A\n"
     ]
    }
   ],
   "source": [
    "img=image.load_img(\"C:\\\\Program Files\\\\Data Collection\\\\test\\\\test\\\\A\\\\15.jpg\")\n",
    "detect(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f7eb6898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PREDICTED LETTER IS  E\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img('C:\\\\Program Files\\\\Data Collection\\\\test\\\\test\\\\E\\\\117.jpg')\n",
    "pred=detect(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "059d11d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE PREDICTED LETTER IS  F\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img('C:\\\\Program Files\\\\Data Collection\\\\test\\\\test\\\\F\\\\109.jpg')\n",
    "pred=detect(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324706d5",
   "metadata": {},
   "outputs": [],
   "source": [
    " ################################### Successfully Tested The Model #################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
